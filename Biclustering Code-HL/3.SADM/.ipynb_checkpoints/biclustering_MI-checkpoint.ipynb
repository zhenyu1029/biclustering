{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "nHO_BZferOJf",
    "outputId": "01841c1b-cace-49e4-e6c4-2a8f6880307b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import sys\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects import pandas2ri\n",
    "import more_itertools as mit\n",
    "from numba import jit\n",
    "drive.mount('/content/gdrive')\n",
    "sys.path.append('/content/gdrive/My Drive/ColabNotebooks/Biclustering/')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UY0JqEAPrSpY",
    "outputId": "a8a2ed68-6280-4896-dba0-859053f5c9c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "R[write to console]: also installing the dependency ‘RcppArmadillo’\n",
      "\n",
      "\n",
      "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/RcppArmadillo_0.9.900.1.0.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 1644927 bytes (1.6 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 1.6 MB\n",
      "\n",
      "\n",
      "R[write to console]: trying URL 'https://cran.rstudio.com/src/contrib/JMI_0.1.0.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 4019 bytes\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 4019 bytes\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/Rtmp6ICuJg/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils = importr(\"utils\")\n",
    "package_name = 'JMI'\n",
    "utils.install_packages(package_name)\n",
    "\n",
    "JMI = importr(\"JMI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPKeIKTCrapR"
   },
   "outputs": [],
   "source": [
    "def r_from_pandas(df):\n",
    "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        df_r = ro.conversion.py2rpy(df)\n",
    "    return df_r\n",
    "\n",
    "def comp_JMI_time_group(df, n_mins=10):\n",
    "    \"\"\"\n",
    "    compute JMI between different groups.\n",
    "    Each group contains n mins time series.\n",
    "    Rows of df are stocks.\n",
    "    Columns of df are time.\n",
    "    \"\"\"\n",
    "    assert(type(n_mins) == int )\n",
    "\n",
    "    num_cols = df.shape[1]\n",
    "    time_points = df.columns\n",
    "    MI= []\n",
    "    time_dict={}\n",
    "    i = 0\n",
    "\n",
    "    for n in range (0, num_cols-n_mins, n_mins):\n",
    "        time_matrix = r_from_pandas(df.iloc[:, n:(n+n_mins)])\n",
    "        time_matrix_next = r_from_pandas(df.iloc[:, (n+n_mins): (n+2*n_mins)])\n",
    "        mi = JMI.JMI(time_matrix, time_matrix_next)[0][0]\n",
    "        MI.append(mi)\n",
    "\n",
    "        time_dict[i] = time_points[n:(n+n_mins)]\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    MI_df = pd.DataFrame(MI)\n",
    "    return MI_df, time_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_stocklist_from_cluster(cluster, i):\n",
    "\n",
    "    #for i in range(data2.shape[0]):\n",
    "\n",
    "    stocks_in_cluster = list(cluster.loc['B_'+str(i+1)])\n",
    "    stocks_in_cluster = [x for x in stocks_in_cluster if str(x) != 'nan']\n",
    "    return stocks_in_cluster\n",
    "\n",
    "\n",
    "def process_raw_return(df, stocks_in_cluster):\n",
    "\n",
    "    df_filtered =df.filter(items=stocks_in_cluster)\n",
    "    df_filtered_T = df_filtered.transpose()\n",
    "    df_filtered_T.columns = df.time\n",
    "    return df_filtered_T\n",
    "\n",
    "# def pairwise_MI(df):\n",
    "#   \"\"\"\n",
    "#   Compute pairwise (columnwise) MI\n",
    "#   \"\"\"\n",
    "#   MI = []\n",
    "#   stocks = df.columns\n",
    "#   for i in range(df.shape[1]-1):\n",
    "#     s1 = r_from_pandas(df.iloc[:,i])\n",
    "#     for j in range(i+1, df.shape[1]):\n",
    "#       s2 = r_from_pandas(df.iloc[:,j])\n",
    "#       mi = JMI.JMI(s1, s2)[0][0]\n",
    "#       MI.append([stocks[i], stocks[j], mi])\n",
    "#   df_MI = pd.DataFrame(MI, columns=['stock1','stock2', 'mi'])\n",
    "#   return df_MI\n",
    "\n",
    "def pairwise_MI(df):\n",
    "    \"\"\"\n",
    "    Compute pairwise (columnwise) MI\n",
    "    \"\"\"\n",
    "    MI = []\n",
    "    stocks = df.columns\n",
    "    for i in range(df.shape[1]):\n",
    "    s1 = r_from_pandas(df.iloc[:,i])\n",
    "    for j in range(df.shape[1]):\n",
    "        s2 = r_from_pandas(df.iloc[:,j])\n",
    "        mi = JMI.JMI(s1, s2)[0][0]\n",
    "        MI.append([stocks[i], stocks[j], mi])\n",
    "    df_MI = pd.DataFrame(MI, columns=['stock1','stock2', 'mi'])\n",
    "    return df_MI\n",
    "\n",
    "\n",
    "def groupwise_in_group(df):\n",
    "    \"\"\"\n",
    "    Compute MI of one vs the rest in the group\n",
    "    \"\"\"\n",
    "    MI = []\n",
    "    stocks = df.columns\n",
    "    for i in range(df.shape[1]):\n",
    "        s = r_from_pandas(df.iloc[:,i])\n",
    "        group = r_from_pandas(df.drop(stocks[i], axis=1))\n",
    "        mi = JMI.JMI(s,group)[0][0]\n",
    "        MI.append([stocks[i], mi])\n",
    "    df_MI = pd.DataFrame(MI, columns = ['stock', 'mi'])\n",
    "    return df_MI\n",
    "\n",
    "def groupwise_out_group(df, df_all):\n",
    "    \"\"\"\n",
    "    Compute MI of one(not in group) vs group\n",
    "    df: clusters_df\n",
    "    df_all: all stocks\n",
    "    \"\"\"\n",
    "    MI = []\n",
    "    stocks_in_cluster = list(df.columns)\n",
    "    all_stocks = list(df_all.index)\n",
    "    stocks_not_in_cluster = list(set(all_stocks) - set(stocks_in_cluster))\n",
    "\n",
    "    time_interval = list(df.index)\n",
    "    for stock in stocks_not_in_cluster:\n",
    "       #print(stock)\n",
    "        s = r_from_pandas(df_all.loc[stock, time_interval])\n",
    "        group = r_from_pandas(df)\n",
    "        mi = JMI.JMI(s,group)[0][0]\n",
    "        #print(mi)\n",
    "        MI.append([stock, mi])\n",
    "    df_MI = pd.DataFrame(MI, columns = ['stock', 'mi'])\n",
    "    return df_MI\n",
    "\n",
    "\n",
    "def column_elimination(MI_list, alpha_C, time_length=3):\n",
    "    J = []\n",
    "    for j, v in enumerate(MI_list):\n",
    "        if v > alpha_C:\n",
    "            J.append(j)\n",
    "\n",
    "    J_time_cluster = []\n",
    "    for group in mit.consecutive_groups(J):\n",
    "        group = list(group)\n",
    "        if len(group) > time_length:\n",
    "            J_time_cluster.append(group)\n",
    "    return J_time_cluster\n",
    "\n",
    "\n",
    "def load_data(raw_return_path, initial_clusterlist_path, e):\n",
    "    df_raw_return = pd.read_csv(raw_return_path +'stockreturn1min'+str(e)+'.csv')\n",
    "    df_initial_clusterlist = pd.read_csv(initial_clusterlist_path +'clusters_'+ str(e) +'.csv')\n",
    "\n",
    "    # preprocess clusters list\n",
    "    df_initial_clusterlist = df_initial_clusterlist.rename(columns={\"0\": \"number\"})\n",
    "    df_initial_clusterlist = df_initial_clusterlist.set_index(['number'])\n",
    "\n",
    "    return df_raw_return, df_initial_clusterlist\n",
    "\n",
    "def get_cluste_stock(initial_clusterlist_path, e, i):\n",
    "\n",
    "    df_initial_clusterlist = pd.read_csv(initial_clusterlist_path +'clusters_'+ str(e) +'.csv')\n",
    "\n",
    "    # preprocess clusters list\n",
    "    df_initial_clusterlist = df_initial_clusterlist.rename(columns={\"0\": \"number\"})\n",
    "    df_initial_clusterlist = df_initial_clusterlist.set_index(['number'])\n",
    "\n",
    "    stocks_in_cluster = get_stocklist_from_cluster(df_initial_clusterlist, i)\n",
    "\n",
    "    return stocks_in_cluster\n",
    "\n",
    "def mi_time_cluster(raw_return_path, stocks_in_cluster, e):\n",
    "\n",
    "    df_raw_return = pd.read_csv(raw_return_path +'stockreturn1min'+str(e)+'.csv')\n",
    "\n",
    "    all_stocks = df_raw_return.columns[3:]\n",
    "    all_stock_data = process_raw_return(df_raw_return, all_stocks)\n",
    "\n",
    "    cluster_data = process_raw_return(df_raw_return, stocks_in_cluster)\n",
    "\n",
    "    cluster_time_MI, time_dict = comp_JMI_time_group(cluster_data, n_mins=10)\n",
    "    MI_list_time = cluster_time_MI.values.reshape(-1)\n",
    "\n",
    "    return MI_list_time\n",
    "\n",
    "def get_time_threshold(raw_return_path, stocks_in_cluster, date,e, percentil=30, daysbefore=10):\n",
    "    MI_list = []\n",
    "    current_day = date.index(e)\n",
    "\n",
    "    for d in date[(current_day-daysbefore): current_day]:\n",
    "\n",
    "        MI_list_time = mi_time_cluster(raw_return_path, stocks_in_cluster, d)\n",
    "        MI_list += list(MI_list_time)\n",
    "\n",
    "    return np.percentile(MI_list, percentil)\n",
    "\n",
    "\n",
    "def get_del_threshold(raw_return_path, stocks_in_cluster, time_cluster, date, e, percentil=70, daysbefore=10):\n",
    "    MI_list = []\n",
    "    current_day = date.index(e)\n",
    "\n",
    "    for d in date[(current_day-daysbefore): current_day]:\n",
    "\n",
    "        df_raw_return = pd.read_csv(raw_return_path +'stockreturn1min'+str(d)+'.csv')\n",
    "        cluster_data = process_raw_return(df_raw_return, stocks_in_cluster)\n",
    "        df_time_cluster = cluster_data.filter(items=time_cluster)\n",
    "        df_time_stock_cluster = df_time_cluster.T\n",
    "\n",
    "        MI_groupwise_in_group = groupwise_in_group(df_time_stock_cluster)\n",
    "        MI_list += list(MI_groupwise_in_group.mi)\n",
    "\n",
    "\n",
    "    return np.percentile(MI_list, percentil)\n",
    "\n",
    "\n",
    "def get_insert_threshold(raw_return_path, df_all, stocks_in_group, time_cluster, date, e, percentil=97, daysbefore=10):\n",
    "\n",
    "    MI_list = []\n",
    "    current_day = date.index(e)\n",
    "    all_stocks = list(df_all.index)\n",
    "\n",
    "    for d in date[(current_day-daysbefore): current_day]:\n",
    "\n",
    "        df_raw_return = pd.read_csv(raw_return_path +'stockreturn1min'+str(d)+'.csv')\n",
    "        cluster_data = process_raw_return(df_raw_return, all_stocks)\n",
    "        df_time_cluster = cluster_data.filter(items=time_cluster)\n",
    "        df_time_stock_cluster = df_time_cluster.T\n",
    "        df_bicluster_deleted = df_time_stock_cluster.filter(items=stocks_in_group)\n",
    "\n",
    "        MI_out_group = groupwise_out_group(df_bicluster_deleted, df_all)\n",
    "\n",
    "        MI_list += list(MI_out_group.mi)\n",
    "\n",
    "    return np.percentile(MI_list, percentil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qM9OteorcZp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# set data path\n",
    "datelist_path = '/content/gdrive/My Drive/ColabNotebooks/Biclustering/'\n",
    "raw_return_path = '/content/gdrive/My Drive/ColabNotebooks/Biclustering/cleanprice_1min/'\n",
    "initial_clusterlist_path = '/content/gdrive/My Drive/ColabNotebooks/Biclustering/JMI_clusters_dis/'\n",
    "\n",
    "# read date\n",
    "datelist = pd.read_csv(datelist_path + 'stockdatelist.csv')\n",
    "\n",
    "# creat date list\n",
    "date = datelist.date.tolist()\n",
    "\n",
    "def main(raw_return_path, initial_clusterlist_path, e):\n",
    "\n",
    "    df_raw_return, df_initial_clusterlist = load_data(raw_return_path, initial_clusterlist_path, e)\n",
    "\n",
    "    all_stocks = df_raw_return.columns[3:]\n",
    "    all_stock_data = process_raw_return(df_raw_return, all_stocks)\n",
    "\n",
    "    for i in range(len(df_initial_clusterlist)):\n",
    "         print('i', i)\n",
    "        stocks_in_cluster = get_stocklist_from_cluster(df_initial_clusterlist, i)\n",
    "        cluster_data = process_raw_return(df_raw_return, stocks_in_cluster)\n",
    "        cluster_time_MI, time_dict = comp_JMI_time_group(cluster_data, n_mins=10)\n",
    "        MI_list_time = cluster_time_MI.values.reshape(-1)\n",
    "\n",
    "        alpha_C = get_time_threshold(raw_return_path, stocks_in_cluster, date, e, percentil=30, daysbefore=10)\n",
    "\n",
    "        J_time_cluster = column_elimination(MI_list_time, alpha_C, time_length=3)\n",
    "\n",
    "        print('J_time_cluster', J_time_cluster)\n",
    "        for j in range(len(J_time_cluster)):\n",
    "            print('j', j)\n",
    "            time_cluster = []\n",
    "            for g in J_time_cluster[j]:\n",
    "                time_cluster += list(time_dict.get(g))\n",
    "\n",
    "            alpha_R_D = get_del_threshold(raw_return_path, stocks_in_cluster, time_cluster, date, e, percentil=70, daysbefore=10)\n",
    "\n",
    "            df_time_cluster = cluster_data.filter(items=time_cluster)\n",
    "            df_time_stock_cluster = df_time_cluster.T\n",
    "\n",
    "            MI_groupwise_in_group = groupwise_in_group(df_time_stock_cluster)\n",
    "            MI_groupwise_in_group_D = MI_groupwise_in_group[MI_groupwise_in_group.mi > alpha_R_D]\n",
    "\n",
    "\n",
    "            stocks_in_group = list(MI_groupwise_in_group_D.stock)\n",
    "\n",
    "            #print('stocks_in_group', stocks_in_group)\n",
    "\n",
    "            if len(stocks_in_group) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                alpha_R_I = get_insert_threshold(raw_return_path, all_stock_data, stocks_in_group, time_cluster, date, e, percentil=97, daysbefore=10)\n",
    "\n",
    "                df_bicluster_deleted = df_time_stock_cluster.filter(items=stocks_in_group)\n",
    "\n",
    "                MI_out_group = groupwise_out_group(df_bicluster_deleted, all_stock_data)\n",
    "                MI_out_group_insert = MI_out_group[MI_out_group.mi > alpha_R_I]\n",
    "\n",
    "                bicluster_stocks = stocks_in_group + list(MI_out_group_insert.stock)\n",
    "\n",
    "                bicluster = pd.DataFrame([bicluster_stocks, time_cluster])\n",
    "                bicluster.to_csv(datelist_path+'res/'+ str(e) + 'bicluster'+ str(i)+'_'+ str(j) +'.csv')\n",
    "                print(i, j, 'is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JMUorwPVrdqj",
    "outputId": "efcd71bc-64c6-4336-f855-f9c957a58e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20130619\n",
      "i 0\n",
      "J_time_cluster [[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]]\n",
      "j 0\n",
      "0 0 is done!\n",
      "i 1\n",
      "J_time_cluster [[0, 1, 2, 3, 4, 5, 6, 7, 8], [15, 16, 17, 18], [33, 34, 35, 36, 37]]\n",
      "j 0\n",
      "j 1\n",
      "1 1 is done!\n",
      "j 2\n",
      "1 2 is done!\n",
      "i 2\n",
      "J_time_cluster []\n",
      "i 3\n",
      "J_time_cluster [[34, 35, 36, 37]]\n",
      "j 0\n",
      "3 0 is done!\n",
      "i 4\n",
      "J_time_cluster [[6, 7, 8, 9, 10], [23, 24, 25, 26], [34, 35, 36, 37]]\n",
      "j 0\n",
      "j 1\n",
      "j 2\n",
      "4 2 is done!\n",
      "20130620\n",
      "i 0\n",
      "J_time_cluster []\n",
      "i 1\n",
      "J_time_cluster [[0, 1, 2, 3, 4, 5, 6, 7], [11, 12, 13, 14, 15, 16, 17, 18, 19], [26, 27, 28, 29, 30, 31], [33, 34, 35, 36, 37]]\n",
      "j 0\n",
      "1 0 is done!\n",
      "j 1\n",
      "1 1 is done!\n",
      "j 2\n",
      "1 2 is done!\n",
      "j 3\n",
      "1 3 is done!\n",
      "i 2\n",
      "J_time_cluster []\n",
      "i 3\n",
      "J_time_cluster []\n",
      "i 4\n",
      "J_time_cluster []\n",
      "i 5\n",
      "J_time_cluster [[19, 20, 21, 22, 23], [28, 29, 30, 31, 32, 33, 34]]\n",
      "j 0\n",
      "5 0 is done!\n",
      "j 1\n",
      "5 1 is done!\n",
      "i 6\n",
      "J_time_cluster [[4, 5, 6, 7, 8, 9], [11, 12, 13, 14, 15], [17, 18, 19, 20, 21, 22, 23, 24], [27, 28, 29, 30, 31, 32, 33]]\n",
      "j 0\n",
      "6 0 is done!\n",
      "j 1\n",
      "6 1 is done!\n",
      "j 2\n",
      "6 2 is done!\n",
      "j 3\n",
      "i 7\n",
      "J_time_cluster [[0, 1, 2, 3], [16, 17, 18, 19], [22, 23, 24, 25, 26, 27, 28]]\n",
      "j 0\n",
      "7 0 is done!\n",
      "j 1\n",
      "7 1 is done!\n",
      "j 2\n",
      "7 2 is done!\n"
     ]
    }
   ],
   "source": [
    "for e in date[116:118]:\n",
    "    print(e)\n",
    "    main(raw_return_path, initial_clusterlist_path, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ir3FDXTvrgb7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Bi_cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
